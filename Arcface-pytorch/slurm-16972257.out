/tmp/slurmd/job16972257/slurm_script: line 8: activate: No such file or directory
157 train iters per epoch:
ResNetFace(
  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (prelu): PReLU(num_parameters=1)
  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): IRBlock(
      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): IRBlock(
      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): IRBlock(
      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): IRBlock(
      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): IRBlock(
      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): IRBlock(
      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): IRBlock(
      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): IRBlock(
      (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (prelu): PReLU(num_parameters=1)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (fc5): Linear(in_features=32768, out_features=512, bias=True)
  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
data_input.shape:torch.Size([16, 1, 128, 128])

data_input tensor([[[[-0.6157, -0.6157, -0.5686,  ..., -0.4824, -0.4431, -0.4196],
          [-0.6392, -0.6392, -0.6235,  ..., -0.5216, -0.4824, -0.4588],
          [-0.6314, -0.6314, -0.6235,  ..., -0.4824, -0.4667, -0.4353],
          ...,
          [-0.6392, -0.6157, -0.5843,  ..., -0.5451, -0.5686, -0.5451],
          [-0.6235, -0.5843, -0.5608,  ..., -0.5373, -0.5373, -0.5373],
          [-0.6627, -0.6392, -0.5922,  ..., -0.5843, -0.5843, -0.5843]]],


        [[[-0.3804, -0.3725, -0.3647,  ..., -0.4196, -0.4196, -0.4275],
          [-0.3804, -0.3725, -0.3647,  ..., -0.4196, -0.4196, -0.4196],
          [-0.3961, -0.3961, -0.3725,  ..., -0.4039, -0.3961, -0.3961],
          ...,
          [-0.3176, -0.3255, -0.3412,  ..., -0.5843, -0.5922, -0.5529],
          [-0.2941, -0.3176, -0.3255,  ..., -0.5843, -0.5843, -0.5765],
          [-0.2941, -0.3569, -0.3647,  ..., -0.5765, -0.5843, -0.5843]]],


        [[[-0.4118, -0.4118, -0.4275,  ..., -0.4824, -0.4824, -0.4980],
          [-0.4118, -0.4275, -0.4275,  ..., -0.4824, -0.4824, -0.4902],
          [-0.4118, -0.4118, -0.4275,  ..., -0.4588, -0.4745, -0.4824],
          ...,
          [-0.3961, -0.4118, -0.4353,  ..., -0.5216, -0.5294, -0.5373],
          [-0.4118, -0.4118, -0.4353,  ..., -0.5294, -0.5216, -0.5373],
          [-0.4431, -0.4275, -0.4275,  ..., -0.5765, -0.5451, -0.5529]]],


        ...,


        [[[-0.5922, -0.5373, -0.5373,  ..., -0.5686, -0.4196, -0.2941],
          [-0.5843, -0.5843, -0.5529,  ..., -0.5843, -0.4353, -0.2235],
          [-0.5922, -0.5843, -0.5843,  ..., -0.5451, -0.3725, -0.1843],
          ...,
          [-0.5843, -0.5843, -0.5843,  ..., -0.1137, -0.0824, -0.0745],
          [-0.5451, -0.5608, -0.5529,  ..., -0.1059, -0.0745, -0.0588],
          [-0.5373, -0.5373, -0.5373,  ..., -0.0745, -0.0745, -0.0745]]],


        [[[-0.7176, -0.7176, -0.6941,  ..., -0.0431, -0.0431, -0.0353],
          [-0.7098, -0.7020, -0.6941,  ..., -0.0431, -0.0431, -0.0431],
          [-0.6941, -0.7020, -0.7098,  ..., -0.0510, -0.0431, -0.0431],
          ...,
          [-0.7490, -0.7490, -0.7490,  ..., -0.4902, -0.4980, -0.4667],
          [-0.7333, -0.7255, -0.7412,  ..., -0.5137, -0.4902, -0.4667],
          [-0.7412, -0.7255, -0.7255,  ..., -0.4824, -0.4824, -0.4824]]],


        [[[-0.5294, -0.5373, -0.5373,  ..., -0.3333, -0.3333, -0.3725],
          [-0.5373, -0.5294, -0.5608,  ..., -0.3333, -0.3647, -0.3961],
          [-0.5451, -0.5373, -0.5451,  ..., -0.4588, -0.4745, -0.4824],
          ...,
          [-0.4275, -0.4118, -0.4196,  ...,  0.0118,  0.0275,  0.0588],
          [-0.4039, -0.4118, -0.4353,  ...,  0.0039,  0.0275,  0.0431],
          [-0.4118, -0.4196, -0.4275,  ..., -0.0118, -0.0039,  0.0196]]]],
       device='cuda:0')



label.shape:torch.Size([16])

label tensor([488, 168, 156, 493,  55,  76,   8, 400, 128, 283, 377, 430, 325, 191,
        179,   0], device='cuda:0')



feature.shape:torch.Size([16, 512])

feature tensor([[ 0.5085, -0.4967,  0.2798,  ...,  0.2432, -0.2763, -0.6950],
        [ 0.5507,  0.0421, -0.0839,  ...,  0.7461, -0.3446, -1.2002],
        [ 0.6265,  0.2971, -0.7244,  ..., -0.5632,  0.4534,  2.0482],
        ...,
        [-1.0638,  0.0966, -0.8504,  ...,  0.8473, -0.0825, -1.1994],
        [-0.7977,  0.0662, -0.4221,  ...,  0.0099,  0.7046, -0.1626],
        [ 0.1352,  0.0840,  0.7059,  ..., -1.2433,  0.0504,  0.3824]],
       device='cuda:0', grad_fn=<NativeBatchNormBackward0>)


 
output.shape:torch.Size([16, 13938])

output tensor([[  0.5781,  -0.2698,  -0.5236,  ...,  -0.5074,   0.3165,  -1.4246],
        [  1.4989,   0.1331,   0.8728,  ...,   0.0190,   1.0140,   0.7945],
        [ -0.8751,   1.1770,  -1.0047,  ...,   0.3318,   2.6321,  -0.9413],
        ...,
        [  1.1864,  -1.2326,  -0.4883,  ...,  -2.3193,   0.4461,  -1.0197],
        [  1.8709,  -3.8948,  -0.6602,  ...,   2.3945,  -4.4673,   0.1428],
        [-13.9019,   0.5254,   0.7764,  ...,  -1.3612,   0.9902,   0.3527]],
       device='cuda:0', grad_fn=<MulBackward0>)



loss 25.21489143371582

